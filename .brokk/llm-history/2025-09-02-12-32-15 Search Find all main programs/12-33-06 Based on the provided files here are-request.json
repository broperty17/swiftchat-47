{
  "messages" : [ {
    "text" : "You are a code expert extracting ALL information relevant to the given goal\nfrom the provided tool call result.\n\nYour output will be given to the agent running the search, and replaces the raw result.\nThus, you must include every relevant class/method name and any\nrelevant code snippets that may be needed later. DO NOT speculate; only use the provided content.\n"
  }, {
    "name" : null,
    "contents" : [ {
      "text" : "<goal>\nFind all main programs, executables, or entry points in this project that might need debugging\n</goal>\n<reasoning>\n\n</reasoning>\n<tool name=\"getFileContents\">\n<file name=\"react-native/package.json\">\n{\n  \"name\": \"BropertyAi\",\n  \"description\": \"Sample Bedrock Cross-platform App - BropertyAi\",\n  \"version\": \"2.4.0\",\n  \"private\": true,\n  \"scripts\": {\n    \"android\": \"react-native run-android\",\n    \"ios\": \"react-native run-ios\",\n    \"build:ios\": \"cd ios && xcodebuild -workspace BropertyAi.xcworkspace -scheme BropertyAi -sdk iphonesimulator -configuration Release -destination generic/platform=iOS CODE_SIGN_IDENTITY=\\\"\\\" CODE_SIGNING_REQUIRED=NO CODE_SIGNING_ALLOWED=NO clean archive | xcpretty\",\n    \"format\": \"npx prettier --check '*.{js,ts}'\",\n    \"lint\": \"npx eslint .\",\n    \"start\": \"react-native start\",\n    \"test\": \"jest\"\n  },\n  \"dependencies\": {\n    \"@bwjohns4/react-native-draggable-flatlist\": \"^4.0.1-patch\",\n    \"@react-native-clipboard/clipboard\": \"^1.14.1\",\n    \"@react-navigation/drawer\": \"^7.1.1\",\n    \"@react-navigation/native\": \"^7.0.14\",\n    \"@react-navigation/native-stack\": \"^7.2.0\",\n    \"mathjax-full\": \"^3.2.2\",\n    \"react\": \"18.2.0\",\n    \"react-native\": \"0.74.1\",\n    \"react-native-code-highlighter\": \"^1.2.2\",\n    \"react-native-compressor\": \"^1.10.1\",\n    \"react-native-dialog\": \"^9.3.0\",\n    \"react-native-document-picker\": \"^9.3.1\",\n    \"react-native-element-dropdown\": \"^2.12.1\",\n    \"react-native-fetch-api\": \"^3.0.0\",\n    \"react-native-file-viewer\": \"^2.1.5\",\n    \"react-native-fs\": \"^2.20.0\",\n    \"react-native-gesture-handler\": \"^2.16.2\",\n    \"react-native-get-random-values\": \"^1.11.0\",\n    \"react-native-gifted-chat\": \"^2.4.0\",\n    \"react-native-haptic-feedback\": \"^2.2.0\",\n    \"react-native-image-picker\": \"^7.2.3\",\n    \"react-native-image-viewing\": \"^0.2.2\",\n    \"react-native-keyboard-controller\": \"^1.18.2\",\n    \"react-native-maps\": \"^1.7.1\",\n    \"react-native-marked\": \"^6.0.7\",\n    \"react-native-math-view\": \"^3.9.5\",\n    \"react-native-mmkv\": \"^2.12.2\",\n    \"react-native-polyfill-globals\": \"^3.1.0\",\n    \"react-native-progress\": \"^5.0.1\",\n    \"react-native-reanimated\": \"^3.10.1\",\n    \"react-native-safe-area-context\": \"^4.10.8\",\n    \"react-native-screens\": \"^4.4.0\",\n    \"react-native-share\": \"^10.2.1\",\n    \"react-native-svg\": \"^15.4.0\",\n    \"react-native-toast-message\": \"^2.2.1\",\n    \"react-native-uuid\": \"^2.0.3\",\n    \"react-native-webview\": \"^13.16.0\",\n    \"react-syntax-highlighter\": \"^15.5.0\",\n    \"readable-stream\": \"^4.7.0\",\n    \"text-decoder\": \"^1.2.3\",\n    \"text-encoding\": \"^0.7.0\",\n    \"uuid\": \"^11.1.0\",\n    \"web-streams-polyfill\": \"^3.2.1\"\n  },\n  \"devDependencies\": {\n    \"@babel/core\": \"^7.26.10\",\n    \"@babel/preset-env\": \"^7.26.9\",\n    \"@babel/runtime\": \"^7.26.10\",\n    \"@react-native/babel-preset\": \"0.74.85\",\n    \"@react-native/eslint-config\": \"0.74.85\",\n    \"@react-native/metro-config\": \"0.74.85\",\n    \"@react-native/typescript-config\": \"0.74.85\",\n    \"@types/marked\": \"5.0.0\",\n    \"@types/react\": \"^18.2.6\",\n    \"@types/react-native-table-component\": \"^1.2.8\",\n    \"@types/react-syntax-highlighter\": \"^15.5.13\",\n    \"@types/react-test-renderer\": \"^18.0.0\",\n    \"@types/uuid\": \"^3.4.13\",\n    \"babel-jest\": \"^29.6.3\",\n    \"core-js\": \"^3.37.1\",\n    \"eslint\": \"^8.57.0\",\n    \"eslint-config-prettier\": \"8.8.0\",\n    \"jest\": \"^29.6.3\",\n    \"patch-package\": \"^8.0.0\",\n    \"prettier\": \"2.8.8\",\n    \"react-test-renderer\": \"18.2.0\",\n    \"typescript\": \"5.0.4\"\n  },\n  \"overrides\": {\n    \"@react-native-clipboard/clipboard\": {\n      \"react-native\": \"~0.74.1\",\n      \"react-native-windows\": \"~0.74.1\"\n    }\n  },\n  \"engines\": {\n    \"node\": \">=18\"\n  },\n  \"license\": \"Apache-2.0\",\n  \"types\": \"module\"\n}\n\n</file>\n\n<file name=\"react-native/index.js\">\n/**\n * @format\n */\nimport 'react-native-polyfill-globals/auto';\nimport { AppRegistry } from 'react-native';\nimport App from './src/App';\n\nAppRegistry.registerComponent('BropertyAi', () => App);\n\n</file>\n\n<file name=\"server/src/main.py\">\nimport base64\nfrom typing import List\nimport uvicorn\nfrom fastapi import FastAPI, HTTPException, Depends, Request as FastAPIRequest\nfrom fastapi.responses import StreamingResponse, PlainTextResponse\nimport boto3\nimport json\nimport random\nimport os\nimport re\nfrom pydantic import BaseModel\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\nfrom typing import Annotated\nfrom urllib.request import urlopen, Request\nimport time\nfrom image_nl_processor import get_native_request_with_ref_image, get_analyse_result\nimport httpx\n\napp = FastAPI()\nsecurity = HTTPBearer()\n\nauth_token = ''\n\n# System prompts untuk setiap bot (hidden dari user)\nBOT_SYSTEM_PROMPTS = {\n    1: \"\"\"Saya adalah Broperty Ai, bot utama yang HANYA merespon komunikasi terkait properti real estate. Jika pertanyaan tidak sesuai dengan topik properti real estate, saya akan secara halus menolaknya.\n\nPERAN UTAMA SAYA:\n1. GERBANG UTAMA - Selalu berkomunikasi dengan user dan internal Broperty, serta menghubungkan kedua pihak tersebut\n2. IDENTIFIKASI KEBUTUHAN USER - Berusaha untuk selalu mengetahui & memenuhi kebutuhan spesifik user terkait properti\n3. MENYAMBUNGKAN KE BERBAGAI FITUR YANG ADA - Menghubungkan user ke sub-bot profesional, web view, atau Google Maps\n\nFITUR AKTIF YANG TERSEDIA:\n- Sub Bot Profesional Ecosystem: Agensi Properti Ai, Notaris Ai, Pengacara Ai, Aparatur Pemerintah Ai, Sertifikasi Elektronik Ai, KPR Bank Ai\n- Web View Integration - Akses konten properti terkini\n- Google Maps Integration - Lokasi dan navigasi properti\n\nSilakan ajukan pertanyaan terkait properti real estate, saya akan menyambungkan Anda ke fitur yang tepat!\"\"\",\n\n    926: \"\"\"Aku adalah Agensi Properti Ai berpengalaman puluhan tahun dalam membantu pembelian dan penjualan properti klien kami. \n\nKEAHLIAN KHUSUS:\n- Konsultasi strategi jual beli properti\n- Analisis harga pasar properti\n- Negosiasi transaksi properti\n- Marketing dan promosi properti\n- Legalitas dasar transaksi properti\n\nSaya TIDAK DAPAT menjawab pertanyaan di luar bidang jual beli properti, dokumen legal mendalam, atau masalah hukum kompleks.\"\"\",\n\n    900: \"\"\"Halo! Aku adalah Notaris Ai. Aku akan memberikan kamu berbagai info terkait apapun itu yang menjadi tugas Notaris.\n\nKEAHLIAN KHUSUS:\n- Pembuatan akta jual beli properti\n- Pengurusan sertifikat tanah dan bangunan\n- Legaliasi dokumen properti\n- Prosedur peralihan hak milik\n- Pengurusan surat ke BPN\n\nSaya TIDAK DAPAT menjawab pertanyaan di luar bidang kenotariatan dan dokumen legal properti.\"\"\",\n\n    901: \"\"\"Halo! Aku adalah Pengacara Ai. Aku akan memberikan kamu berbagai info berita terkait tugas Pengacara yang berkaitan dengan properti.\n\nKEAHLIAN KHUSUS:\n- Penanganan sengketa properti\n- Pemeriksaan dokumen transaksi jual beli\n- Pendampingan hukum di pengadilan untuk kasus properti\n- Kontrak dan perjanjian properti\n- Advokasi hak kepemilikan properti\n\nSaya TIDAK DAPAT menjawab pertanyaan di luar bidang hukum properti.\"\"\",\n\n    911: \"\"\"Halo! Aku adalah Aparatur Pemerintah Ai seperti kepala desa, Lurah, Camat, Bupati, Walikota dll yang membantu terkait segala sesuatu yang berhubungan dengan properti.\n\nKEAHLIAN KHUSUS:\n- Pengurusan prosedur kepemilikan properti di pemerintahan\n- Informasi perizinan bangunan\n- Proses administrasi tanah\n- Koordinasi dengan instansi pemerintah terkait properti\n- Kebijakan pemerintah tentang properti\n\nSaya TIDAK DAPAT menjawab pertanyaan di luar bidang administrasi pemerintahan terkait properti.\"\"\",\n\n    920: \"\"\"Halo! Aku adalah asisten Program Sertifikasi Elektronik Ai yang akan membantu anda dalam pengurusan sertifikat elektronik di BPN.\n\nKEAHLIAN KHUSUS:\n- Pembuatan Sertifikasi Elektronik\n- Prosedur digitalisasi sertifikat\n- Teknologi sertifikat elektronik\n- Integrasi sistem elektronik BPN\n- Keamanan sertifikat digital\n\nSaya TIDAK DAPAT menjawab pertanyaan di luar Program Sertifikasi Elektronik.\"\"\",\n\n    922: \"\"\"Halo! Aku adalah asisten pengajuan KPR Bank Ai yang bertugas memberikan info dan membantu anda terkait segala sesuatu mengenai KPR berbagai Bank di Indonesia.\n\nKEAHLIAN KHUSUS:\n- Informasi KPR berbagai bank\n- Syarat dan prosedur pengajuan KPR\n- Perbandingan suku bunga KPR\n- Kalkulasi angsuran KPR\n- Restrukturisasi KPR\n\nSaya TIDAK DAPAT menjawab pertanyaan di luar KPR Bank.\"\"\"\n}\nCACHE_DURATION = 120000\ncache = {\n    \"latest_version\": \"\",\n    \"last_check\": 0\n}\n\n\nclass ImageRequest(BaseModel):\n    prompt: str\n    refImages: List[dict] | None = None\n    modelId: str\n    region: str\n    width: int\n    height: int\n\n\nclass ConverseRequest(BaseModel):\n    messages: List[dict] = []\n    modelId: str\n    enableThinking: bool | None = None\n    region: str\n    system: List[dict] | None = None\n    botId: int | None = None\n\n\nclass StreamOptions(BaseModel):\n    include_usage: bool = True\n\n\nclass GPTRequest(BaseModel):\n    model: str\n    messages: List[dict]\n    stream: bool = True\n    stream_options: StreamOptions\n    botId: int | None = None\n\n\nclass ModelsRequest(BaseModel):\n    region: str\n\n\nclass TokenRequest(BaseModel):\n    region: str\n\n\nclass UpgradeRequest(BaseModel):\n    os: str\n    version: str\n\n\ndef get_api_key_from_ssm(use_cache_token: bool):\n    global auth_token\n    if use_cache_token and auth_token != '':\n        return auth_token\n    ssm_client = boto3.client('ssm')\n    api_key_name = os.environ['API_KEY_NAME']\n    try:\n        response = ssm_client.get_parameter(\n            Name=api_key_name,\n            WithDecryption=True\n        )\n        auth_token = response['Parameter']['Value']\n        return auth_token\n    except Exception as error:\n        raise HTTPException(status_code=401,\n                            detail=f\"Error: Please create your API Key in Parameter Store, {str(error)}\")\n\n\ndef verify_api_key(credentials: Annotated[HTTPAuthorizationCredentials, Depends(security)],\n                   use_cache_token: bool = True):\n    if credentials.credentials != get_api_key_from_ssm(use_cache_token):\n        raise HTTPException(status_code=401, detail=\"Invalid API Key\")\n    return credentials.credentials\n\n\ndef verify_and_refresh_token(credentials: Annotated[HTTPAuthorizationCredentials, Depends(security)]):\n    return verify_api_key(credentials, use_cache_token=False)\n\n\nasync def create_bedrock_command(request: ConverseRequest) -> tuple[boto3.client, dict]:\n    model_id = request.modelId\n    region = request.region\n\n    client = boto3.client(\"bedrock-runtime\", region_name=region)\n\n    max_tokens = 4096\n    if model_id.startswith('meta.llama'):\n        max_tokens = 2048\n    if 'deepseek.r1' in model_id or 'claude-opus-4' in model_id:\n        max_tokens = 32000\n    if 'claude-3-7-sonnet' in model_id or 'claude-sonnet-4' in model_id:\n        max_tokens = 64000\n\n    for message in request.messages:\n        if message[\"role\"] == \"user\":\n            for content in message[\"content\"]:\n                if 'image' in content:\n                    image_bytes = base64.b64decode(content['image']['source']['bytes'])\n                    content['image']['source']['bytes'] = image_bytes\n                if 'video' in content:\n                    video_bytes = base64.b64decode(content['video']['source']['bytes'])\n                    content['video']['source']['bytes'] = video_bytes\n                if 'document' in content:\n                    document_bytes = base64.b64decode(content['document']['source']['bytes'])\n                    content['document']['source']['bytes'] = document_bytes\n\n    command = {\n        \"inferenceConfig\": {\"maxTokens\": max_tokens},\n        \"messages\": request.messages,\n        \"modelId\": model_id\n    }\n\n    if request.enableThinking:\n        command['additionalModelRequestFields'] = {\n            \"reasoning_config\": {\n                \"type\": \"enabled\",\n                \"budget_tokens\": 16000\n            }\n        }\n\n    # Prioritaskan system prompt dari botId jika tersedia\n    if request.botId is not None and request.botId in BOT_SYSTEM_PROMPTS:\n        command[\"system\"] = [{\"text\": BOT_SYSTEM_PROMPTS[request.botId]}]\n    elif request.system is not None:\n        command[\"system\"] = request.system\n\n    return client, command\n\n\n@app.post(\"/api/converse/v3\")\nasync def converse_v3(request: ConverseRequest,\n                      _: Annotated[str, Depends(verify_api_key)]):\n    try:\n        client, command = await create_bedrock_command(request)\n\n        def event_generator():\n            try:\n                response = client.converse_stream(**command)\n                for item in response['stream']:\n                    yield json.dumps(item) + '\\n\\n'\n            except Exception as err:\n                yield f\"Error: {str(err)}\"\n\n        return StreamingResponse(event_generator(), media_type=\"text/event-stream\")\n\n    except Exception as error:\n        return PlainTextResponse(f\"Error: {str(error)}\", status_code=500)\n\n\n@app.post(\"/api/converse/v2\")\nasync def converse_v2(request: ConverseRequest,\n                      _: Annotated[str, Depends(verify_api_key)]):\n    try:\n        client, command = await create_bedrock_command(request)\n\n        def event_generator():\n            try:\n                response = client.converse_stream(**command)\n                for item in response['stream']:\n                    yield json.dumps(item)\n            except Exception as err:\n                yield f\"Error: {str(err)}\"\n\n        return StreamingResponse(event_generator(), media_type=\"text/event-stream\")\n\n    except Exception as error:\n        return PlainTextResponse(f\"Error: {str(error)}\", status_code=500)\n\n\n@app.post(\"/api/image\")\nasync def gen_image(request: ImageRequest,\n                    _: Annotated[str, Depends(verify_api_key)]):\n    model_id = request.modelId\n    prompt = request.prompt\n    ref_images = request.refImages\n    width = request.width\n    height = request.height\n    region = request.region\n    client = boto3.client(\"bedrock-runtime\",\n                          region_name=region)\n    if (ref_images is None or model_id.startswith(\"stability.\")) and contains_chinese(prompt):\n        prompt = get_english_prompt(client, prompt)\n    return get_image(client, model_id, prompt, ref_images, width, height)\n\n\n@app.post(\"/api/token\")\nasync def get_token(request: TokenRequest,\n                    _: Annotated[str, Depends(verify_api_key)]):\n    region = request.region\n    try:\n        client_role_arn = os.environ.get('CLIENT_ROLE_ARN')\n        if not client_role_arn:\n            return {\"error\": \"CLIENT_ROLE_ARN environment variable not set\"}\n        sts_client = boto3.client('sts', region_name=region)\n        session_name = f\"SwiftChatClient-{int(time.time())}\"\n        response = sts_client.assume_role(\n            RoleArn=client_role_arn,\n            RoleSessionName=session_name,\n            DurationSeconds=3600\n        )\n        credentials = response['Credentials']\n        return {\n            \"accessKeyId\": credentials['AccessKeyId'],\n            \"secretAccessKey\": credentials['SecretAccessKey'],\n            \"sessionToken\": credentials['SessionToken'],\n            \"expiration\": credentials['Expiration'].isoformat()\n        }\n    except Exception as e:\n        print(f\"Error assuming role: {e}\")\n        return {\"error\": str(e)}\n\n\n@app.post(\"/api/models\")\nasync def get_models(request: ModelsRequest,\n                     _: Annotated[str, Depends(verify_api_key)]):\n    region = request.region\n    client = boto3.client(\"bedrock\",\n                          region_name=region)\n\n    try:\n        response = client.list_foundation_models()\n        if response.get(\"modelSummaries\"):\n            model_names = set()\n            text_model = []\n            image_model = []\n            for model in response[\"modelSummaries\"]:\n                need_cross_region = \"INFERENCE_PROFILE\" in model[\"inferenceTypesSupported\"]\n                if (model[\"modelLifecycle\"][\"status\"] == \"ACTIVE\"\n                        and (\"ON_DEMAND\" in model[\"inferenceTypesSupported\"] or need_cross_region)\n                        and not model[\"modelId\"].endswith(\"k\")\n                        and model[\"modelName\"] not in model_names):\n                    if (\"TEXT\" in model.get(\"outputModalities\", []) and\n                            model.get(\"responseStreamingSupported\")):\n                        if need_cross_region:\n                            region_prefix = region.split(\"-\")[0]\n                            if region_prefix == 'ap':\n                                region_prefix = 'apac'\n                            model_id = region_prefix + \".\" + model[\"modelId\"]\n                        else:\n                            model_id = model[\"modelId\"]\n                        text_model.append({\n                            \"modelId\": model_id,\n                            \"modelName\": model[\"modelName\"]\n                        })\n                    elif \"IMAGE\" in model.get(\"outputModalities\", []):\n                        image_model.append({\n                            \"modelId\": model[\"modelId\"],\n                            \"modelName\": model[\"modelName\"]\n                        })\n                    model_names.add(model[\"modelName\"])\n            return {\"textModel\": text_model, \"imageModel\": image_model}\n        else:\n            return []\n    except Exception as e:\n        print(f\"bedrock error: {e}\")\n        return {\"error\": str(e)}\n\n\n@app.post(\"/api/upgrade\")\nasync def upgrade(request: UpgradeRequest,\n                  _: Annotated[str, Depends(verify_and_refresh_token)]):\n    new_version = get_latest_version()\n    total_number = calculate_version_total(request.version)\n    need_upgrade = False\n    url = ''\n    if total_number > 0:\n        need_upgrade = total_number < calculate_version_total(new_version)\n        if need_upgrade:\n            download_prefix = \"https://github.com/aws-samples/swift-chat/releases/download/\"\n            if request.os == 'android':\n                url = download_prefix + new_version + \"/SwiftChat.apk\"\n            elif request.os == 'mac':\n                url = download_prefix + new_version + \"/SwiftChat.dmg\"\n    return {\"needUpgrade\": need_upgrade, \"version\": new_version, \"url\": url}\n\n\n@app.post(\"/api/openai\")\nasync def converse_openai(request: GPTRequest, raw_request: FastAPIRequest):\n    auth_header = raw_request.headers.get(\"Authorization\")\n    if not auth_header or not auth_header.startswith(\"Bearer \"):\n        raise HTTPException(status_code=401, detail=\"Invalid auth header\")\n    openai_api_key = auth_header.split(\" \")[1]\n    request_url = raw_request.headers.get(\"request_url\")\n    if not request_url or not request_url.startswith(\"http\"):\n        raise HTTPException(status_code=401, detail=\"Invalid request url\")\n    http_referer = raw_request.headers.get(\"HTTP-Referer\")\n    x_title = raw_request.headers.get(\"X-Title\")\n\n    # Tambahkan system prompt berdasarkan botId jika tersedia\n    request_data = request.model_dump()\n    if request.botId is not None and request.botId in BOT_SYSTEM_PROMPTS:\n        # Cari dan tambahkan system message jika belum ada\n        has_system_message = any(msg.get(\"role\") == \"system\" for msg in request_data[\"messages\"])\n        if not has_system_message:\n            request_data[\"messages\"].insert(0, {\n                \"role\": \"system\",\n                \"content\": BOT_SYSTEM_PROMPTS[request.botId]\n            })\n\n    async def event_generator():\n        async with httpx.AsyncClient() as client:\n            try:\n                async with client.stream(\n                        \"POST\",\n                        request_url,\n                        json=request_data,\n                        headers={\n                            \"Authorization\": f\"Bearer {openai_api_key}\",\n                            \"Content-Type\": \"application/json\",\n                            \"Accept\": \"text/event-stream\",\n                            **({\"HTTP-Referer\": http_referer} if http_referer else {}),\n                            **({\"X-Title\": x_title} if x_title else {})\n                        }\n                ) as response:\n                    async for line in response.aiter_bytes():\n                        if line:\n                            yield line\n\n            except Exception as err:\n                print(\"error:\", err)\n                yield f\"Error: {str(err)}\".encode('utf-8')\n\n    return StreamingResponse(event_generator(), media_type=\"text/event-stream\")\n\n\ndef calculate_version_total(version: str) -> int:\n    versions = version.split(\".\")\n    total_number = 0\n    if len(versions) == 3:\n        total_number = int(versions[0]) * 10000 + int(versions[1]) * 100 + int(versions[2])\n    return total_number\n\n\ndef get_latest_version() -> str:\n    timestamp = int(time.time() * 1000)\n    if cache[\"last_check\"] > 0 and timestamp - cache[\"last_check\"] < CACHE_DURATION:\n        return cache[\"latest_version\"]\n    req = Request(\n        f\"https://api.github.com/repos/aws-samples/swift-chat/tags\",\n        headers={\n            'User-Agent': 'Mozilla/5.0'\n        }\n    )\n    try:\n        with urlopen(req) as response:\n            content = response.read().decode('utf-8')\n            latest_version = json.loads(content)[0]['name']\n            cache[\"latest_version\"] = latest_version\n            cache[\"last_check\"] = timestamp\n            return json.loads(content)[0]['name']\n    except Exception as error:\n        print(f\"Error occurred when get github tag: {error}\")\n    return '0.0.0'\n\n\ndef get_image(client, model_id, prompt, ref_image, width, height):\n    try:\n        seed = random.randint(0, 2147483647)\n        native_request = {}\n        if model_id.startswith(\"amazon\"):\n            if ref_image is None:\n                native_request = {\n                    \"taskType\": \"TEXT_IMAGE\",\n                    \"textToImageParams\": {\"text\": prompt},\n                    \"imageGenerationConfig\": {\n                        \"numberOfImages\": 1,\n                        \"quality\": \"standard\",\n                        \"cfgScale\": 8.0,\n                        \"height\": height,\n                        \"width\": width,\n                        \"seed\": seed,\n                    },\n                }\n            else:\n                native_request = get_native_request_with_ref_image(client, prompt, ref_image, width, height)\n        elif model_id.startswith(\"stability.\"):\n            native_request = {\n                \"prompt\": prompt,\n                \"output_format\": \"jpeg\",\n                \"mode\": \"text-to-image\",\n            }\n            if ref_image:\n                native_request['mode'] = 'image-to-image'\n                native_request['image'] = ref_image[0]['source']['bytes']\n                native_request['strength'] = 0.5\n            else:\n                native_request['aspect_ratio'] = \"1:1\"\n        request = json.dumps(native_request)\n        response = client.invoke_model(modelId=model_id, body=request)\n        model_response = json.loads(response[\"body\"].read())\n        base64_image_data = model_response[\"images\"][0]\n        return {\"image\": base64_image_data}\n    except Exception as error:\n        error_msg = str(error)\n        print(f\"Error occurred: {error_msg}\")\n        return {\"error\": error_msg}\n\n\ndef get_english_prompt(client, prompt):\n    global_prompt = f\"Translate to English image prompt, output only English translation.\"\n    return get_analyse_result(client, prompt, global_prompt)\n\n\ndef contains_chinese(text):\n    pattern = re.compile(r'[\\u4e00-\\u9fff]')\n    match = pattern.search(text)\n    return match is not None\n\n\nif __name__ == \"__main__\":\n    print(\"Starting webserver...\")\n    uvicorn.run(app, host=\"0.0.0.0\", port=int(os.environ.get(\"PORT\", \"8080\")))\n\n</file>\n\n<file name=\"react-native/ios/SwiftChat/main.m\">\n#import <UIKit/UIKit.h>\n\n#import \"AppDelegate.h\"\n\nint main(int argc, char *argv[])\n{\n  @autoreleasepool {\n    return UIApplicationMain(argc, argv, nil, NSStringFromClass([AppDelegate class]));\n  }\n}\n\n</file>\n</tool>\n"
    } ]
  } ],
  "parameters" : {
    "modelName" : null,
    "temperature" : null,
    "topP" : null,
    "frequencyPenalty" : null,
    "presencePenalty" : null,
    "maxOutputTokens" : null,
    "stopSequences" : [ ],
    "toolSpecifications" : [ ],
    "toolChoice" : null,
    "responseFormat" : null,
    "maxCompletionTokens" : null,
    "logitBias" : { },
    "parallelToolCalls" : null,
    "seed" : null,
    "user" : null,
    "store" : null,
    "metadata" : { },
    "serviceTier" : null,
    "reasoningEffort" : null
  }
}